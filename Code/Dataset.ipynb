{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77ddfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80909ba1",
   "metadata": {},
   "source": [
    "# Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5bbf428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ami (C:/Users/nayan/.cache/huggingface/datasets/edinburghcstr___ami/ihm/0.0.0/0d128d0aa8145d0f16f3d5b4da86c5d5759dbe9e8f947fda04b25edb56442bd5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9a5fc5b2c742e4a4e50e818787d21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['meeting_id', 'text', 'begin_time', 'end_time', 'speaker_id'],\n",
       "        num_rows: 108502\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['meeting_id', 'text', 'begin_time', 'end_time', 'speaker_id'],\n",
       "        num_rows: 13098\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['meeting_id', 'text', 'begin_time', 'end_time', 'speaker_id'],\n",
       "        num_rows: 12643\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"edinburghcstr/ami\", \"ihm\")\n",
    "ds = ds.remove_columns([\"audio_id\", \"audio\", \"microphone_id\"])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rename_columns({'begin_time':'start_time', 'speaker_id': 'speaker'})\n",
    "ds['train'].to_csv(r'D:\\\\MACHINE LEARNING\\\\Meeting\\\\Data/train1.csv')\n",
    "ds['validation'].to_csv(r'D:\\MACHINE LEARNING\\Meeting\\Data/validation.csv')\n",
    "ds['test'].to_csv(r'D:\\MACHINE LEARNING\\Meeting\\Data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1187547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(seconds):\n",
    "    if type(seconds) is float:\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        seconds = int(seconds % 60)\n",
    "\n",
    "        return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "    return seconds\n",
    "        \n",
    "def modify_csv(df):\n",
    "    df = df.astype({'text': str, 'start_time': float, 'end_time': float,'speaker': str })\n",
    "    df['start_time'] = df['start_time'].apply(convert_time)\n",
    "    df['end_time'] = df['start_time'].apply(convert_time)\n",
    "    desired_order = ['meeting_id','start_time', 'end_time', 'speaker', 'text']\n",
    "    df = df.reindex(columns=desired_order)\n",
    "    return df\n",
    "\n",
    "def update_csv(name):\n",
    "    path = os.path.join(r\"D:\\\\MACHINE LEARNING\\\\Meeting\\\\Data\", f\"{name}.csv\")\n",
    "    df = pd.read_csv(path)\n",
    "    df = update_csv(df)\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4720cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Training Data\n",
      "Updating Validation Data\n",
      "Updating Test Data\n"
     ]
    }
   ],
   "source": [
    "print(\"Updating Training Data\")\n",
    "path = 'D:\\MACHINE LEARNING\\Meeting\\Data/train.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = modify_csv(df)\n",
    "df.to_csv(path, index=False)\n",
    "print(\"Updating Validation Data\")\n",
    "path = 'D:\\MACHINE LEARNING\\Meeting\\Data/validation.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = modify_csv(df)\n",
    "df.to_csv(path, index=False)\n",
    "print(\"Updating Test Data\")\n",
    "path = 'D:\\MACHINE LEARNING\\Meeting\\Data/test.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = modify_csv(df)\n",
    "df.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "164abfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12643 entries, 0 to 12642\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   meeting_id  12643 non-null  object\n",
      " 1   start_time  12643 non-null  object\n",
      " 2   end_time    12643 non-null  object\n",
      " 3   speaker     12643 non-null  object\n",
      " 4   text        12643 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 494.0+ KB\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\MACHINE LEARNING\\Meeting\\Data/test.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609dc14",
   "metadata": {},
   "source": [
    "###  Working on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "224a3e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for D:\\MACHINE LEARNING\\Meeting\\Data\\test.csv\n",
      "Done for D:\\MACHINE LEARNING\\Meeting\\Data\\train.csv\n",
      "Done for D:\\MACHINE LEARNING\\Meeting\\Data\\validation.csv\n"
     ]
    }
   ],
   "source": [
    "data_path = \"D:\\MACHINE LEARNING\\Meeting\\Data\"\n",
    "\n",
    "# Get all the CSV files in the data folder\n",
    "csv_files = glob.glob(data_path + \"/*.csv\")\n",
    "\n",
    "# Loop over the CSV files\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    filtered_df = df[~df['meeting_id'].str.startswith(('EN', 'IB', 'IN'))]  # Took only the scenerio meetings\n",
    "    filtered_df = filtered_df.drop('meeting_id', axis=1)\n",
    "    print(f\"Done for {csv_file}\")\n",
    "    filtered_df.to_csv(csv_file, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42d0b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (79109, 4),Validation: (7549, 4) ,Test: (7520, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r\"D:\\MACHINE LEARNING\\Meeting Analysis\\Data\\train.csv\")\n",
    "valid_df = pd.read_csv(r\"D:\\MACHINE LEARNING\\Meeting Analysis\\Data\\validation.csv\")\n",
    "test_df = pd.read_csv(r\"D:\\MACHINE LEARNING\\Meeting Analysis\\Data\\test.csv\")\n",
    "print(f'Train: {train_df.shape},Validation: {valid_df.shape} ,Test: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99748cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextEnv",
   "language": "python",
   "name": "textenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
